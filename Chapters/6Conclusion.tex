\section{Conclusion}

In the context of global and local optimization methods, the goal is to solve the unconstrained minimization problem described in \ref{eq:8}. Local optimization methods, such as gradient descent, are primarily used for convex functions with the aim of finding a global minimum. Gradient descent can also be applied to non-convex functions, but due to its reliance on gradient information, it can easily become trapped in a local minimum and fail to locate a global minimum.

Stochastic Gradient Descent (SGD), which is suitable for large-scale functions arising in machine learning, often finds a local minimum to be sufficient in practice. Functions in machine learning are complex, containing numerous local minima, saddle points, and flat regions. Searching for a global minimum within such spaces can be computationally expensive and time-consuming. In many cases, a satisfactory solution can be provided by a good local minimum. Moreover, a model that achieves the global minimum on training data might not generalize well to new data due to overfitting, whereas a local minimum could strike a better balance between fitting the data and generalizing to new examples as discussed in \cite[282-290]{Goodfellow-et-al-2016}

Global optimization methods serve as an alternative to gradient-based optimization techniques and aim to find a global minimum. These methods are especially important for solving non-convex functions. In contrast to local optimization methods, global optimization methods employ various search strategies to explore the solution space more thoroughly, thereby increasing the likelihood of identifying the global optimum, as discussed in \cite[1-5]{horst1995handbook}. 
