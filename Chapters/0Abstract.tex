\thispagestyle{plain}
\begin{center}
    \Large
    \textbf{Optimization Techniques for Unconstrained Minimization}

    \vspace{0.4cm}
    \large
    (Stochastic) Optimization

    \vspace{0.4cm}
    \textbf{Burak Ekici}

    \vspace{0.9cm}
    \textbf{Abstract}
\end{center}
Optimization is a critical aspect of many machine learning and deep learning applications, and two common subfields of mathematical optimization for solving optimization problems are convex optimization and stochastic optimization. Convex optimization assumes that the cost function is convex, while stochastic optimization algorithms, such as stochastic gradient descent (SGD), do not require the cost function to be convex in general. However, convexity assumptions are used in the analysis of these algorithms to ensure convergence guarantees and the existence of a unique minimum.
This thesis provides a comprehensive explanation of traditional deterministic gradient descent, including its variations such as fixed step size and backtracking line search. Subsequently, the focus is on stochastic gradient descent (SGD) and its applications. Moreover, derivative-free optimization methods, such as simulated annealing (SA) and particle swarm optimization (PSO), are discussed to tackle multi-dimensional non-convex functions. A comparison is made of the performance of these algorithms in different scenarios, and the importance of convexity assumptions in the analysis of different optimization algorithms, including SGD, is explored. The impact of hyper-parameter tuning on the convergence of these algorithms is also evaluated. The results of the analysis provide valuable insights for practitioners and researchers in the field of machine learning and deep learning.
\begin{comment}
Optimization is a critical aspect of many machine learning and deep learning applications, and two common subfields of mathematical optimization for solving optimization problems are convex optimization and stochastic optimization. Convex optimization assumes that the cost function is convex, while stochastic optimization algorithms such as SGD do not require the cost function to be convex in general. However, convexity assumptions are used in the analysis of these algorithms to ensure convergence guarantees and the existence of a unique minimum. In this thesis, a comprehensive explanation of traditional deterministic gradient descent is provided, including its variations such as fixed step size and backtracking line search. Subsequently, the focus is on stochastic gradient descent (SGD) and its variation, Adams, analyzing their mathematical formulations and applications. A comparison is made of the performance of these algorithms in different scenarios, and the importance of convexity assumptions in the analysis of different optimization algorithms, including SGD and its variation Adams, is explored. The impact of hyperparameter tuning on the convergence of these algorithms is also evaluated. The results of the analysis provide valuable insights for practitioners and researchers in the field of machine learning and deep learning.
\end{comment}