\section{Appendix A: Source Code}
\lstlistoflistings
\subsection{Packages}
\begin{lstlisting}[language=Python, label={lst:code1}, mathescape=true, breaklines=true]
import numpy as np
import matplotlib.pyplot as plt 
import matplotlib.ticker
from matplotlib import cm 
from matplotlib.colors import ListedColormap
from mpl_toolkits.mplot3d import Axes3D
from collections import defaultdict
from fractions import Fraction
from scipy.optimize import basinhopping
from scipy.optimize import minimize
import pyswarms as ps
from pyswarms.single.global_best import GlobalBestPSO
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import torch.nn.functional as F
\end{lstlisting}

\subsection{Gradient descent on quadratic function - fixed step size}
\begin{lstlisting}[language=Python, label={lst:code6}, mathescape=true, breaklines=true, escapechar=|]
def fun(x: list) -> float:
    return (x[0]**2 + 10*(x[1]**2)) / 2
    
def grad(x: list) -> float:
    return np.array([float(x[0]), float(10*x[1])]) 

def min_gd_i_fixed(fun, x0, grad, t): 
    dx = -grad(x0)
    mylist = []
    while (np.max(np.abs(dx)) > 1.e-7):
        mylist.append(float((x0[0]**2 + 10*(x0[1]**2)) / 2))
        x0 = x0 + t*dx
        dx = -grad(x0)   
    return mylist

def min_gd_i_fixed_len_lastval(fun, x0, grad, t): 
    dx = -grad(x0)
    mylist = []
    while (np.max(np.abs(dx)) > 1.e-7):
        mylist.append(float((x0[0]**2 + 10*(x0[1]**2)) / 2))
        x0 = x0 + t*dx
        dx = -grad(x0)   
    return len(mylist), mylist[-1]

def min_gd_ii_fixed(fun, x0, grad, t):
    dx = -grad(x0)
    while (np.max(np.abs(dx)) > 1e-07):
        x0 = x0 + t*dx
        dx = -grad(x0)   
    return list(x0)

def min_gd_iii_fixed(fun, x0, grad, t):
    dx = -grad(x0)
    minsequencelist = []
    while (np.max(np.abs(dx)) > 1e-07):
        minsequencelist.append(list(x0))
        x0 = x0 + t*dx
        dx = -grad(x0)  
    minsequencelist.append(list(x0))
    return(minsequencelist)


t_vals = [Fraction(2, 11), Fraction(2, 22), Fraction(2, 44), Fraction(2, 88)] |\label{line:13}|
colors = ['green', '#8bc34a', 'orange', '#a50026']
markers = ['o', '^', 'v', 'd']
fig, axs = plt.subplots(1, 2, figsize=(15, 5))

for i, t in enumerate(t_vals):
    var_fixed = min_gd_i_fixed(fun, [10, 2], grad, t)
    axs[0].plot(var_fixed[:31], color=colors[i], marker=markers[i], mfc=colors[i], label=r"$\tau={{{}/{}}}$".format(t.numerator, t.denominator))
    var_fixed = np.array(var_fixed)
    error = np.abs(var_fixed - 0)
    axs[1].plot(error, color=colors[i], marker=markers[i], mfc=colors[i], label=r"$\tau={{{}/{}}}$".format(t.numerator, t.denominator))



axs[0].set_ylabel(r'Function value', fontdict={'fontsize': 13, 'fontweight': 'medium'}) 
axs[0].set_xlabel(r'num iteration $k$', fontdict={'fontsize': 13, 'fontweight': 'medium'}) 
axs[0].set_title(r"$f$ evaluated at points $x^{(k)}$ for different values of $\tau$", fontdict={'fontsize': 12, 'fontweight': 'medium'}) 
axs[0].legend()

axs[1].set_ylabel(r"Error", labelpad=0.1, fontdict={'fontsize': 13, 'fontweight': 'medium'})
axs[1].set_xlabel(r'num iteration $k$', fontdict={'fontsize': 13, 'fontweight': 'medium'}) 
axs[1].set_title(r'Error with respect to the exact global minimum $0$', fontdict={'fontsize': 12, 'fontweight': 'medium'})
axs[1].set_yscale('log')
axs[1].legend()
plt.show()

fig_table = plt.figure(figsize=(4, 5))
ax_table = fig_table.add_subplot(111)
len_lastval = [min_gd_i_fixed_len_lastval(fun, [10,2], grad, t) for t in [2/11, 1/11, 1/22, 1/44]]
len_lastval_format = [(l, "{:.2e}".format(value)) for l, value in len_lastval]
dct = defaultdict(tuple)
dct[Fraction(2, 11)] = len_lastval_format[0]
dct[Fraction(1, 11)] = len_lastval_format[1]
dct[Fraction(1, 22)] = len_lastval_format[2]
dct[Fraction(1, 44)] = len_lastval_format[3]
table_data = []

for k, v in dct.items():
    table_data.append([f"{k.numerator}/{k.denominator}", v[0], v[1]])

table = ax_table.table(cellText=table_data, cellLoc='center', colLabels=["Step Size", "Iterations", "Last Value"], loc="center")
table.auto_set_font_size(False)
table.auto_set_column_width(col='all')
table.set_fontsize(12)
cell_height = 4.3
table.scale(1, cell_height)
ax_table.axis("off")
ax_table.set_title("Summary Table", fontsize=16)
plt.show() |\label{line:14}|

def min_gd_iv_fixed(fun, x0, grad, t, tol): |\label{line:17}|
    dx = -grad(x0)
    minsequencelist = []
    while (np.max(np.abs(dx)) > tol):
        minsequencelist.append(list(x0))
        x0 = x0 + t*dx
        dx = -grad(x0)  
    minsequencelist.append(list(x0))
    return len(minsequencelist)

def plot_tol(tol):
    t_values = np.linspace(2/11, 1/50, num=400)
    output_values = np.zeros_like(t_values)
    for i, t in enumerate(t_values):
        output_values[i] = min_gd_iv_fixed(fun, [10,2], grad, t, tol=tol)
    plt.plot(t_values, output_values, label=fr"$\eta$ = {tol}")

    tol_values = [1e-2, 1e-4, 1e-6, 1e-8]
    fig, ax = plt.subplots()
    for tol in tol_values:
        plot_tol(tol)
    
    ax.set_xlabel(r'Step size $\tau$')
    ax.set_ylabel(r'Number of iterations $k$')
    ax.set_title(r'The number of iterations as a function of the step size $\tau$ for different tolerances')
    plt.legend()
    plt.show() |\label{line:18}|

width_of_panel = 4.5 |\label{line:15}|
height_of_panel = 3
d = 500
plt.figure(figsize=(width_of_panel, height_of_panel), dpi=d)

x1 = np.arange(-11, 11.1, 0.1)
x2 = np.arange(-3., 3.1, 0.1)
x1, x2 = np.meshgrid(x1, x2)
z = (x1**2 +10*(x2**2)) / 2

levels = [1, 4, 7, 10]
cp1 = plt.contour(x1, x2, z, levels=levels)
cp2 = plt.contour(x1, x2, z)

plt.clabel(cp1, inline=1, fontsize=6)
plt.clabel(cp2, inline=1, fontsize=6)
plt.xlabel('x1')
plt.ylabel('x2')
plt.plot(x_one(min_gd_iii_fixed(fun, [10,2], grad, 1/5.5)), x_two(min_gd_iii_fixed(fun, [10,2], grad, 1/5.5)), color='green')
plt.plot(x_one(min_gd_iii_fixed(fun, [10,2], grad, 1/5.5))[:], x_two(min_gd_iii_fixed(fun, [10,2], grad, 1/5.5))[:], "or", markerfacecolor="None", markeredgecolor='black', markeredgewidth=1.1, markersize=2.6)
plt.plot(x_one(min_gd_iii_fixed(fun, [10,2], grad, 1/51)), x_two(min_gd_iii_fixed(fun, [10,2], grad, 1/51)), color='red')
plt.plot(x_one(min_gd_iii_fixed(fun, [10,2], grad, 1/51))[:], x_two(min_gd_iii_fixed(fun, [10,2], grad, 1/51))[:], "or", markerfacecolor="None", markeredgecolor='black', markeredgewidth=1.1, markersize=2.6)

plt.annotate("$x^0$", fontsize = 7.5, xy=(10,2), xytext=(4.9, 1.95), arrowprops=None, color='green')
plt.annotate(",", fontsize = 7.5, xy=(10,2), xytext=(5.25, 1.95))
plt.annotate("$x^0$", fontsize = 7.5, xy=(10,2), xytext=(5.65, 1.95), color='red')
plt.arrow(6.5, 2, 2.9, 0, head_width=0.125, head_length=0.3, fc='beige')
plt.annotate("$x^1$", fontsize = 7.5, xy=(8.181818181818182,-1.6363636363636367), xytext=(4.5,-1.7), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3', facecolor='g'), color='green')
plt.annotate("$x^1$", fontsize = 7.5, xy=(9.803921568627452,1.607843137254902), xytext=(6.3,1.55), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3',facecolor='r'), color='red')
plt.show() |\label{line:16}|
\end{lstlisting}

\newpage

\subsection{Gradient descent on quadratic function - line search}\label{GD-on-qd}
\begin{lstlisting}[language=Python, label={lst:code3}, mathescape=true, breaklines=true, escapechar=|]
def min_gd_i(fun, x0, grad): 
    alpha = 0.3
    beta = 0.8
    dx = -grad(x0)
    mylist = []
    while (np.max(np.abs(dx)) > 1.e-7):
        t = 1
        while fun(x0+t*dx) > fun(x0) - alpha*t*dx.T@dx:
            t *= beta
        mylist.append(float(x0[0]**2 + 10*(x0[1]**2) / 2))
        x0 = x0 + t*dx
        dx = -grad(x0)      
    return mylist

var = min_gd_i(fun, [10,2], grad) |\label{line:p5}|
plt.plot(var[0:15], color='magenta', marker='o',mfc='purple')
plt.ylabel('Surface function value') 
plt.xlabel('num iteration') 
plt.title("Surface function evaluated at x for each iteration") 
plt.show() 

plt.plot(var[:31], color='magenta', marker='o',mfc='purple')
plt.ylabel(r"$f(x^{(k)})$", fontsize=12) 
plt.xlabel(r'num iteration $k$', fontsize=12) 
plt.title(r'Error with respect to the exact global minimum $0$')
plt.yscale('log')
plt.show()  |\label{line:p6}|

def min_gd_ii(fun, x0, grad):
    alpha = 0.3
    beta = 0.8
    dx = -grad(x0)
    while (np.max(np.abs(dx)) > 1e-07):
        t = 1
        while fun(x0+t*dx) > fun(x0) - alpha*t*dx.T@dx:
            t *= beta
        x0 = x0 + t*dx
        dx = -grad(x0)   
    return list(x0)
    
def min_gd_iii(fun, x0, grad):
    alpha = 0.3
    beta = 0.8
    dx = -grad(x0)
    minsequencelist = []
    while (np.max(np.abs(dx)) > 1e-07):
        t = 1
        while fun(x0+t*dx) > fun(x0) - alpha*t*dx.T@dx:
            t *= beta
        minsequencelist.append(list(x0))
        x0 = x0 + t*dx
        dx = -grad(x0)  
    minsequencelist.append(list(x0))
    return(minsequencelist)
    
width_of_panel = 4.5 |\label{line:p7}|
height_of_panel = 3
d = 500
plt.figure(figsize=(width_of_panel, height_of_panel), dpi=d)
x1 = np.arange(-11, 11.1, 0.1)
x2 = np.arange(-3., 3.1, 0.1)
x1, x2 = np.meshgrid(x1, x2)
z = (x1**2 +10*(x2**2)) / 2

levels = [1, 4, 7, 10]
cp1 = plt.contour(x1, x2, z, levels=levels)
cp2 = plt.contour(x1, x2, z)

plt.clabel(cp1, inline=1, fontsize=6)
plt.clabel(cp2, inline=1, fontsize=6)
plt.xlabel('x1')
plt.ylabel('x2')
plt.plot(x_one(min_gd_iii(fun, [10,2], grad)), x_two(min_gd_iii(fun, [10,2], grad)), color='lightseagreen')
plt.plot(x_one(min_gd_iii(fun, [10,2], grad))[:], x_two(min_gd_iii(fun, [10,2], grad))[:], "or", markerfacecolor="None", markeredgecolor='black', markeredgewidth=1.1, markersize=2.6)
plt.annotate("$x^0$", fontsize = 8.5, xy=(10,2), xytext=(6,2.4), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3',facecolor='r'))
plt.annotate("$x^1$", fontsize = 8.5, xy=(8.322278399999998,-1.3554432000000016), xytext=(6,-2), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3',facecolor='r'))
plt.show() |\label{line:p8}|
\end{lstlisting}
\subsection{Gradient descent on non-quadratic function}\label{GD-on-nqd}
\begin{lstlisting}[language=Python, label={lst:code4}, mathescape=true, breaklines=true, escapechar=|]
def fun2(x: list):
    return np.exp((x[0] + 3*x[1] - 0.1)) + np.exp((x[0] - 3*x[1] - 0.1)) + np.exp((-x[0] - 0.1))

def grad2(x: list) -> float:
    return np.array([np.exp((x[0] + 3*x[1] - 0.1)) + np.exp((x[0] - 3*x[1] - 0.1)) - np.exp((-x[0] - 0.1)), 3*np.exp((x[0] + 3*x[1] - 0.1)) - 3*np.exp((x[0] - 3*x[1] - 0.1))])

def min_gd2_i(fun2, x0, grad2):
    alpha = 0.1
    beta = 0.7
    dx = -grad2(x0)
    mylist2 = []
    while (np.max(np.abs(dx)) > 1e-07):
        t = 1
        while fun2(x0+t*dx) > fun2(x0) - alpha*t*dx.T@dx:
            t *= beta
        mylist2.append(np.exp((x0[0] + 3*x0[1] - 0.1)) + np.exp((x0[0] - 3*x0[1] - 0.1)) + np.exp((-x0[0] - 0.1)))
        x0 = x0 + t*dx
        dx = -grad2(x0)
    return mylist2

var2 = min_gd2_i(fun2, [-1,0.5], grad2) |\label{line:p9}|
plt.plot(var2[0:7], color='magenta', marker='o',mfc='purple')
plt.ylabel('Surface function value') 
plt.xlabel('num iteration') 
plt.title("Surface function evaluated at x for each iteration") 
plt.show() 

ervar2  = [y - var2[-1] for y in var2]
plt.plot(ervar2[:30], color='magenta', marker='o',mfc='purple')
plt.ylabel(r"$g(x^{(k)}) - p^{*}$", fontsize=12) 
plt.xlabel(r'num iteration $k$', fontsize=12) 
plt.title('Error')
plt.yscale('log')
plt.show() |\label{line:p10}|

def min_gd2_ii(fun2, x0, grad2):
    alpha = 0.1
    beta = 0.7
    dx = -grad2(x0)
    while (np.max(np.abs(dx)) > 1e-07):
        t = 1
        while fun2(x0+t*dx) > fun2(x0) - alpha*t*dx.T@dx:
            t *= beta
        x0 = x0 + t*dx
        dx = -grad2(x0)
    return list(x0)

def min_gd2_iii(fun2, x0, grad2):
    alpha = 0.1
    beta = 0.7
    dx = -grad2(x0)
    minsequencelist = []
    while (np.max(np.abs(dx)) > 1e-07):
        t = 1
        while fun2(x0+t*dx) > fun2(x0) - alpha*t*dx.T@dx:
            t *= beta
        minsequencelist.append(list(x0))
        x0 = x0 + t*dx
        dx = -grad2(x0)
    minsequencelist.append(list(x0))
    return(minsequencelist)

width_of_panel = 4.5 |\label{line:p11}|
height_of_panel = 2
d = 1000
plt.figure(figsize=(width_of_panel, height_of_panel), dpi=d)
x1 = np.arange(-2, 0.9, 0.1)
x2 = np.arange(-0.6, 0.7, 0.1)
x1, x2 = np.meshgrid(x1, x2)
z = np.exp((x1 + 3*x2 - 0.1)) + np.exp((x1 - 3*x2 - 0.1)) + np.exp((-x1 - 0.1))
cp = plt.contour(x1, x2, z)
plt.clabel(cp, inline=1, fontsize=6)
plt.xlabel('x1')
plt.ylabel('x2')
plt.plot(x_one(min_gd2_iii(fun2, [-1,0.5], grad2)), x_two(min_gd2_iii(fun2, [-1,0.5], grad2)), color='lightseagreen')
plt.plot(x_one(min_gd2_iii(fun2, [-1,0.5], grad2))[:], x_two(min_gd2_iii(fun2, [-1,0.5], grad2))[:], "or", markerfacecolor="None", markeredgecolor='black', markeredgewidth=1.1, markersize=2.6)
plt.annotate("$x^0$", fontsize = 8.5, xy=(-1,0.5), xytext=(-1.33,0.395), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3',facecolor='r'))
plt.annotate("$x^1$", fontsize = 8.5, xy=(-0.8498286423309029,-0.21474344992625538), xytext=(-1.3,-0.35), arrowprops=dict(arrowstyle = '-|>', connectionstyle = 'Arc3',facecolor='r'))
plt.show() |\label{line:p12}|
\end{lstlisting}


\subsection{Gradient descent - Ackley's function}\label{GD-Ack}
\begin{lstlisting}[language=Python, label={lst:code7}, mathescape=true, breaklines=true, escapechar=|]
def ackley(x):
    d = 100
    A = 20
    sum_sq = sum([(xi**2) for xi in x])
    term1 = -A * np.exp(-0.2 * np.sqrt(sum_sq/d))
    term2 = -np.exp(sum([np.cos(2*np.pi*xi) for xi in x])/d)
    y = term1 + term2 + A + np.exp(1)
    return y

def ackley_grad(x):
    d = 100
    A = 20
    n = len(x)
    sum_sq = sum([(xi**2) for xi in x])
    term1 = -2 * np.array(x) * np.exp(-0.2 * np.sqrt(sum_sq/n)) / np.sqrt(n*d)
    term2 = np.array([np.sin(2*np.pi*xi) for xi in x]) * (2*np.pi/d)
    grad = term1 + term2
    return grad

def gradient_descent_backtrack_ackley(ackley, ackley_grad, x0, tol, alpha=0.1, beta=0.8, max_iter=1000): 
    x = x0
    fx = ackley(x)
    grad = ackley_grad(x)
    iter = 0
    mylist = []
    while iter < max_iter and np.linalg.norm(grad) > tol:
        t = 1
        while ackley(x - t*grad) > fx - alpha*t*(grad.T@grad):
            t = beta*t
        mylist.append(ackley(x))
        x = x - t*grad
        fx = ackley(x)
        grad = ackley_grad(x)
        iter += 1
    return mylist 

random_vector = np.random.uniform(low=-32.768, high=32.768 size=100) |\label{line:21}|

var3 = gradient_descent_backtrack_ackley(ackley, ackley_grad, p, 1e-6, alpha=0.1, beta=0.8, max_iter=1000) |\label{line:22}|
fig, axs = plt.subplots(1, 2, figsize=(14, 5))
axs[0].plot(var3[:22], color='darkred', marker='',mfc='purple', linewidth=4)
axs[0].set_ylabel('function value', fontsize=13) 
axs[0].set_xlabel(r'num iteration $k$', fontsize=13) 
axs[0].set_title(r"Convergence with starting vector x randomly chosen", fontsize=11.5) 

var4 = gradient_descent_backtrack_ackley(ackley, ackley_grad, 100*[0.4], 1e-06, alpha=0.1, beta=0.8, max_iter=1000)
axs[1].plot(var4[:22], color='olive', marker='',mfc='purple', linewidth=4)
axs[1].set_ylabel('function value', fontsize=13) 
axs[1].set_xlabel(r'num iteration $k$', fontsize=13) 
axs[1].set_title(r"Convergence with starting vector $x=(0.4,\ldots,0.4)$", fontsize=11.5) 
plt.show() |\label{line:23}|
\end{lstlisting}

\subsection{Supplementary functions}
\begin{lstlisting}[language=Python, label={lst:code2}, mathescape=true, breaklines=true]
def f(x, y): 
    return - np.abs(x) * np.abs(y)

def x_one(lst: list[list]) -> list:
    mylist = []
    for i in lst:
        mylist.append(i[0])
    return mylist

def x_two(lst: list[list]) -> list:
    mylist = []
    for i in lst:
        mylist.append(i[1])
    return mylist

def objective(x1, x2):
    return -20.0 * exp(-0.2 * sqrt(0.5 * (x1**2 + x2**2)))-exp(0.5 * (cos(2 * pi * x1)+cos(2 * pi * x2))) + e + 20

\end{lstlisting}
\subsection{Supplementary plots}
\begin{lstlisting}[language=Python, label={lst:code5}, mathescape=true, breaklines=true, escapechar=|]
fig = plt.figure(figsize=(10, 8))  |\label{line:p1}|
ax = fig.add_subplot(projection='3d')
ax.set_xlabel('x1 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_ylabel('x2 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_zlabel('z axis', fontsize=10, fontweight='bold', fontfamily='serif')
x1 = np.arange(-10, 10, 0.05)
x2 = np.arange(-10, 10, 0.05)
x1, x2 = np.meshgrid(x1, x2)
f = (x1**2 + 10*(x2**2)) / 2
surface = ax.plot_surface(x1, x2, f, cmap=cm.coolwarm, linewidth=0)
fig.colorbar(surface, shrink=0.5)
ax.view_init(elev=14, azim=125)
plt.show()

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(projection='3d')
ax.set_xlabel('x1 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_ylabel('x2 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_zlabel('z axis', fontsize=10, fontweight='bold', fontfamily='serif')
x1 = np.arange(-4, 4, 0.05)
x2 = np.arange(-4, 4, 0.05)
x1, x2 = np.meshgrid(x1, x2)
f = np.sin(0.5*x1**2 - 0.25*x2**2 + 3) / (0.5 + 0.25*x1**2 + x2**2)
surface = ax.plot_surface(x1, x2, f, cmap=cm.coolwarm, linewidth=0)
fig.colorbar(surface, shrink=0.5)
ax.view_init(elev=18, azim=125)
plt.show()  |\label{line:p2}|

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(projection='3d')
ax.set_title('3D surface plot of function of the form e^x')
ax.set_xlabel('x1 axis')
ax.set_ylabel('x2 axis')
ax.set_zlabel('z axis')
x1 = np.arange(-1, 2, 0.05)
x2 = np.arange(-1, 1, 0.05)
x1, x2 = np.meshgrid(x1, x2)
f = np.exp((x1 + 3*x2 - 0.1)) + np.exp((x1 - 3*x2 - 0.1)) + np.exp((-x2 - 0.1))
surface = ax.plot_surface(x1, x2, f, cmap=cm.coolwarm, linewidth=0)
fig.colorbar(surface, shrink=0.5)
plt.show()

fig = plt.figure(figsize=(10, 8)) |\label{line:19}|
ax = fig.add_subplot(projection='3d')
ax.set_xlabel('x1 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_ylabel('x2 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_zlabel('z axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_facecolor((1.0, 1.0, 1.0))
x1 = np.arange(-32.768, 32.768, 0.05)
x2 = np.arange(-32.768, 32.768, 0.05)
x1, x2 = np.meshgrid(x1, x2)
f = objective(x1, x2)
surface = ax.plot_surface(x1, x2, f, cmap='coolwarm', linewidth=0)
ax.view_init(elev=15, azim=45)
fig.colorbar(surface, shrink=0.5)
plt.show()

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(projection='3d')
ax.set_xlabel('x1 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_ylabel('x2 axis', fontsize=10, fontweight='bold', fontfamily='serif')
ax.set_zlabel('z axis', fontsize=10, fontweight='bold', fontfamily='serif')
x1 = np.arange(-5, 5, 0.025)
x2 = np.arange(-5, 5, 0.025)
x1, x2 = np.meshgrid(x1, x2)
f = objective(x1, x2)
surface = ax.plot_surface(x1, x2, f, cmap='inferno', edgecolor='none', alpha=0.8)
fig.colorbar(surface, shrink=0.5, aspect=10)
surface.set_facecolor((0,0,0,0))
ax.set_facecolor((1.0, 1.0, 1.0))
ax.set_box_aspect([1,1,0.4])
ax.auto_scale_xyz([-5,5],[-5,5],[0,10])
ax.dist = 12
ax.view_init(elev=15, azim=45)
plt.show() |\label{line:20}|
\end{lstlisting}



















-











