@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, S. and Vandenberghe, L.},
  year={2004},
  publisher={Cambridge university press}
}

@book{adams2013calculus,
  title={Calculus: A Complete Course},
  author={Adams, R.A. and Essex, C.},
  isbn={9780321781079},
  url={https://books.google.nl/books?id=5aaEMAEACAAJ},
  year={2013},
  publisher={Pearson}
}

@inbook{doi:https://doi.org/10.1002/9780470173862.app3,
publisher = {John W. \& Sons, Ltd},
isbn = {9780470173862},
title = {Appendix C: Positive Semidefinite and Positive Definite Matrices},
booktitle = {Parameter Estimation for Scientists and Engineers},
chapter = {},
pages = {259-263},
doi = {https://doi.org/10.1002/9780470173862.app3},
year = {2007},
abstract = {Summary This chapter contains sections titled: Real Positive Semidefinite and Positive Definite Matrices Complex Positive Semidefinite and Positive Definite Matrices}
}

@online{GDlips,
  title = {Gradient-based optimization},
  author = {J.A. Fessler},
  url = {https://web.eecs.umich.edu/~fessler/course/598/l/n-03-gd.pdf},
  note = {Accessed: 16-1-2020},
}

@online{matrixnorms,
  title = {Matrix Norms},
  url = {https://www2.karlin.mff.cuni.cz/~congreve/SS2019_NUMMATH/2020_03_25.pdf},
  note = {Accessed: 25-3-2020},
}

@online{GDandLS,
  author = {C. Wang},
  title = {Notes on Convex Optimization},
  url = {https://chunpai.github.io/assets/note/1__Gradient_Descent_and_Line_Search.pdf},
  year = {2016},
  note = {Accessed: 1-3-2016},
}

@article{Test_functions,
 author  = {M. Jamil and X.-S. Yang},
 title   = {A Literature Survey of Benchmark Functions For Global Optimization Problems},
 journal = {Int. Journal of Mathematical Modelling and Numerical Optimisation},
 year    = {2013},
 volume  = {4},
 number  = {2},
 pages   = {150--194},
 month   = aug,
 url     = {https://doi.org/10.48550/arXiv.1308.4008},
 }

 @online{coursenotesML,
    author = {Peyr√©, G.},
    title = {Optimization for machine learning},
    url = {https://mathematical-tours.github.io/book-sources/optim-ml/OptimML.pdf},
    year = {2021},
    note = {Course notes on March 30, 2021}
}

@article{murata,
author = {Murata, N.},
year = {1998},
month = {05},
pages = {},
title = {A Statistical Study on On-line Learning}
}

@techreport{turinici2021convergence,
  doi = {10.5281/ZENODO.4638695},
  url = {https://zenodo.org/record/4638695},
  author = {Turinici, G.},
  keywords = {Stochastic Gradient Descent, Neural Network, SGD, Adam, RMSprop, Gabriel TURINICI},
  language = {en},
  title = {The convergence of the Stochastic Gradient Descent (SGD) : a self-contained proof},
  publisher = {Zenodo},
  year = {2021},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@book{horst1995handbook,
  title={Handbook of Global Optimization},
  editor={Horst, R. and Pardalos, P.M.},
  year={1995},
  publisher={Springer Science \& Business Media},
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={I. Goodfellow and Y. Bengio and A. Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{XIANG1997216,
title = {Generalized simulated annealing algorithm and its application to the Thomson model},
journal = {Physics Letters A},
volume = {233},
number = {3},
pages = {216-220},
year = {1997},
issn = {0375-9601},
doi = {https://doi.org/10.1016/S0375-9601(97)00474-X},
url = {https://www.sciencedirect.com/science/article/pii/S037596019700474X},
author = {Y. Xiang and D.Y Sun and W. Fan and X.G Gong},
abstract = {Based on the Tsallis statistics, the generalized simulated annealing algorithm (GSA) is tested and developed. Studies on the Thomson model show that the GSA is more efficient than the classical simulated annealing and the fast simulated annealing. The fluctuation of energy is reduced drastically. The convergence to the global minimum is fast. We believe the GSA algorithm is a powerful method to find the global minimum in more realistic problems, like the equilibrium structure of big clusters.}
}

@Inbook{Henderson2003,
author="Henderson, D.
and Jacobson, S.H.
and Johnson, A.W.",
editor="Glover, F.
and Kochenberger, G.A.",
title="The Theory and Practice of Simulated Annealing",
bookTitle="Handbook of Metaheuristics",
year="2003",
publisher="Springer US",
address="Boston, MA",
pages="287--319",
abstract="Simulated annealing is a popular local search meta-heuristic used to address discrete and, to a lesser extent, continuous optimization problems. The key feature of simulated annealing is that it provides a means to escape local optima by allowing hill-climbing moves (i.e., moves which worsen the objective function value) in hopes of finding a global optimum. A brief history of simulated annealing is presented, including a review of its application to discrete and continuous optimization problems. Convergence theory for simulated annealing is reviewed, as well as recent advances in the analysis of finite time performance. Other local search algorithms are discussed in terms of their relationship to simulated annealing. The chapter also presents practical guidelines for the implementation of simulated annealing in terms of cooling schedules, neighborhood functions, and appropriate applications.",
isbn="978-0-306-48056-0",
doi="10.1007/0-306-48056-5_10",
url="https://doi.org/10.1007/0-306-48056-5_10"
}

@article{metropolis1953equation,
  title={Equation of State Calculations by Fast Computing Machines},
  author={Metropolis, N. and Rosenbluth, A.W. and Rosenbluth, M.N and Teller, A.H. and Teller, E.},
  journal={The Journal of Chemical Physics},
  volume={21},
  number={6},
  pages={1087--1092},
  year={1953},
  doi={10.1063/1.1699114},
  publisher={AIP Publishing}
}

@article{Kennedy1995,
  author       = {Kennedy, J. and Eberhart, R.},
  title        = {Particle Swarm Optimization},
  journaltitle = {Proceedings of the IEEE International Conference on Neural Networks},
  year         = {1995},
  volume       = {4},
  pages        = {1942-1948},
  doi          = {10.1109/ICNN.1995.488968},
}

@article{PSO,
author = {Pereira, G.},
year = {2011},
month = {05},
pages = {},
title = {Particle Swarm Optimization}
}

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, L.},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, A. and Gross, S. and Massa, F. and Lerer, A. and Bradbury, J. and Chanan, G. and Killeen, T., et al.},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@book{python,
 author = {Van Rossum, G. and Drake, F.L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

@book{bishop2006,
  title={Pattern recognition and machine learning},
  author={Bishop, C.M.},
  year={2006},
  publisher={Springer}
}

@book{james2013,
  title={An introduction to statistical learning},
  author={James, G. and Witten, D. and Hastie, T. and Tibshirani, R.},
  volume={112},
  year={2013},
  publisher={Springer}
}

@article{ThesisCode2023,
  author={Ekici, B.}, 
  title={Deterministic and Stochastic Schemes for Unconstrained Optimization}, 
  year={2023}, 
  url={https://github.com/bekici/Bachelor_thesis_bekici} 
}

@misc{bengio2012practical,
      title={Practical recommendations for gradient-based training of deep architectures}, 
      author={Bengio, Y.},
      year={2012},
      eprint={1206.5533},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
} 

@book{reed1999neural,
  title={Neural Smithing: Supervised Learning in Feedforward Artificial Neural Networks},
  author={Reed, R.D. and Marks II, R.J.},
  year={1999},
  publisher={MIT Press},
  edition={Illustrated}
}

@unpublished{CastroNotes,
  author = {Castro, R.},
  title = {The Empirical Distribution Function and the Histogram},
  note = {Lecture notes in Sequential and Nonparametric Statistics course},
  institution = {Eindhoven University of Technology},
  year = {2013},
  url={https://www.win.tue.nl/~rmcastro/2WS17/files/ecdf_hist.pdf}
}

@book{stein2005real,
  title={Real Analysis: Measure Theory, Integration, and Hilbert Spaces},
  author={Stein, E.M. and Shakarchi, R.},
  year={2005},
  publisher={Princeton University Press}
}

@misc{kahle2006,
  author = {Kahle, T.},
  title = {The Glivenko Cantelli Theorem and its Generalizations},
  year = {2006},
  month = {augustus},
  day = {21},
  url = {http://staff.ustc.edu.cn/~zwp/teach/Math-Stat/Kahle.pdf}
}
